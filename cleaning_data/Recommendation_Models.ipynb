{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = pd.read_csv(r'C:\\Users\\DELL\\Desktop\\audible_insights\\data\\cleaned_books.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Number of Reviews_x</th>\n",
       "      <th>Price_x</th>\n",
       "      <th>Number of Reviews_y</th>\n",
       "      <th>Price_y</th>\n",
       "      <th>Description</th>\n",
       "      <th>Listening Time</th>\n",
       "      <th>Ranks and Genre</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Think Like a Monk: The Secret of How to Harnes...</td>\n",
       "      <td>Jay Shetty</td>\n",
       "      <td>313.0</td>\n",
       "      <td>10080.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>10080</td>\n",
       "      <td>Over the past three years, Jay Shetty has beco...</td>\n",
       "      <td>10 hours and 54 minutes</td>\n",
       "      <td>,#1 in Audible Audiobooks &amp; Originals (See Top...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ikigai: The Japanese Secret to a Long and Happ...</td>\n",
       "      <td>Héctor García</td>\n",
       "      <td>3658.0</td>\n",
       "      <td>615.0</td>\n",
       "      <td>3682.0</td>\n",
       "      <td>615</td>\n",
       "      <td>Brought to you by Penguin.</td>\n",
       "      <td>3 hours and 23 minutes</td>\n",
       "      <td>,#2 in Audible Audiobooks &amp; Originals (See Top...</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Subtle Art of Not Giving a F*ck: A Counter...</td>\n",
       "      <td>Mark Manson</td>\n",
       "      <td>20174.0</td>\n",
       "      <td>10378.0</td>\n",
       "      <td>20306.0</td>\n",
       "      <td>10378</td>\n",
       "      <td>In this generation-defining self-help guide, a...</td>\n",
       "      <td>5 hours and 17 minutes</td>\n",
       "      <td>,#3 in Audible Audiobooks &amp; Originals (See Top...</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atomic Habits: An Easy and Proven Way to Build...</td>\n",
       "      <td>James Clear</td>\n",
       "      <td>4614.0</td>\n",
       "      <td>888.0</td>\n",
       "      <td>4678.0</td>\n",
       "      <td>888</td>\n",
       "      <td>Brought to you by Penguin.</td>\n",
       "      <td>5 hours and 35 minutes</td>\n",
       "      <td>,#5 in Audible Audiobooks &amp; Originals (See Top...</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Life's Amazing Secrets: How to Find Balance an...</td>\n",
       "      <td>Gaur Gopal Das</td>\n",
       "      <td>4302.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>4308.0</td>\n",
       "      <td>1005</td>\n",
       "      <td>Stop going through life,  Start growing throug...</td>\n",
       "      <td>6 hours and 25 minutes</td>\n",
       "      <td>,#6 in Audible Audiobooks &amp; Originals (See Top...</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Book Name          Author  \\\n",
       "0  Think Like a Monk: The Secret of How to Harnes...      Jay Shetty   \n",
       "1  Ikigai: The Japanese Secret to a Long and Happ...   Héctor García   \n",
       "2  The Subtle Art of Not Giving a F*ck: A Counter...     Mark Manson   \n",
       "3  Atomic Habits: An Easy and Proven Way to Build...     James Clear   \n",
       "4  Life's Amazing Secrets: How to Find Balance an...  Gaur Gopal Das   \n",
       "\n",
       "   Number of Reviews_x  Price_x  Number of Reviews_y  Price_y  \\\n",
       "0                313.0  10080.0                371.0    10080   \n",
       "1               3658.0    615.0               3682.0      615   \n",
       "2              20174.0  10378.0              20306.0    10378   \n",
       "3               4614.0    888.0               4678.0      888   \n",
       "4               4302.0   1005.0               4308.0     1005   \n",
       "\n",
       "                                         Description           Listening Time  \\\n",
       "0  Over the past three years, Jay Shetty has beco...  10 hours and 54 minutes   \n",
       "1                         Brought to you by Penguin.   3 hours and 23 minutes   \n",
       "2  In this generation-defining self-help guide, a...   5 hours and 17 minutes   \n",
       "3                         Brought to you by Penguin.   5 hours and 35 minutes   \n",
       "4  Stop going through life,  Start growing throug...   6 hours and 25 minutes   \n",
       "\n",
       "                                     Ranks and Genre  Rating  \n",
       "0  ,#1 in Audible Audiobooks & Originals (See Top...     4.9  \n",
       "1  ,#2 in Audible Audiobooks & Originals (See Top...     4.6  \n",
       "2  ,#3 in Audible Audiobooks & Originals (See Top...     4.4  \n",
       "3  ,#5 in Audible Audiobooks & Originals (See Top...     4.6  \n",
       "4  ,#6 in Audible Audiobooks & Originals (See Top...     4.6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Content-Based Filtering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Books:\n",
      "1765               The Classic Tales Podcast, Season Five\n",
      "1262    The Facebook Effect: The Inside Story of the C...\n",
      "2710    Built to Serve: Find Your Purpose and Become t...\n",
      "3046    The Rise and Fall of the Dinosaurs: The Untold...\n",
      "27                             Raavan: Enemy of Aryavarta\n",
      "2279                             On the Origin of Species\n",
      "2315                   God Save the Hon'ble Supreme Court\n",
      "925                  Social Media Marketing Workbook 2020\n",
      "376     50 Self-Help Classics to Guide You to Financia...\n",
      "927                     10 Essential Pieces of Literature\n",
      "Name: Book Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\DELL\\Desktop\\audible_insights\\data\\cleaned_books.csv')\n",
    "\n",
    "data['Description'] = data['Description'].fillna('')  \n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(data['Description'])  \n",
    "\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Function to get recommendations based on cosine similarity\n",
    "def get_recommendations(book_name, cosine_sim=cosine_sim):\n",
    "    \n",
    "    # Check if the book exists in the dataset\n",
    "    if book_name not in data['Book Name'].values:\n",
    "        return f\"Book '{book_name}' not found in the dataset. Showing recommendations for the first book instead.\"\n",
    "\n",
    "    # Get index of the book that matches the title\n",
    "    idx = data.index[data['Book Name'] == book_name].tolist()[0]\n",
    "\n",
    "    # pairwise similarity scores\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Books sort based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get indices most similar books\n",
    "    sim_scores = sim_scores[1:11]  # To get top 10 similar books\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Returns top 10 most similar books\n",
    "    return data['Book Name'].iloc[book_indices]\n",
    "\n",
    "#To Get recommendations for a book\n",
    "book_name = 'Think Like a Monk: The Secret of How to Harness the Power of Positivity and Be Happy Now'  \n",
    "recommended_books = get_recommendations(book_name)\n",
    "\n",
    "print(\"Recommended Books:\")\n",
    "print(recommended_books)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering-Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering books using KMeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(tfidf_matrix)\n",
    "\n",
    "# Assign cluster labels-books\n",
    "books_df['cluster'] = kmeans.labels_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Collaborative Filtering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Books:\n",
      "                                              Book Name             Author\n",
      "0     Think Like a Monk: The Secret of How to Harnes...         Jay Shetty\n",
      "1765             The Classic Tales Podcast, Season Five    Agatha Christie\n",
      "1262  The Facebook Effect: The Inside Story of the C...  David Kirkpatrick\n",
      "2710  Built to Serve: Find Your Purpose and Become t...    Evan Carmichael\n",
      "3046  The Rise and Fall of the Dinosaurs: The Untold...     Steve Brusatte\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\DELL\\Desktop\\audible_insights\\data\\cleaned_books.csv')\n",
    "\n",
    "data['Description'] = data['Description'].fillna('')  \n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(data['Description']) \n",
    "\n",
    "# Collaborative Filtering using Nearest Neighbors (KNN)\n",
    "knn = NearestNeighbors(n_neighbors=5, metric='cosine') \n",
    "knn.fit(tfidf_matrix)\n",
    "\n",
    "# For given book, recommend the top 5 similar books,but instead of passing just one row, pass the entire matrix for similarity calculation\n",
    "distances, indices = knn.kneighbors(tfidf_matrix[0:1])  # passing 2D array with one sample\n",
    "\n",
    "recommended_books = data.iloc[indices[0]]\n",
    "\n",
    "print(\"Recommended Books:\")\n",
    "print(recommended_books[['Book Name', 'Author']])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content-based Filtering Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# content-based recommendations\n",
    "def get_content_based_recommendations(book_name, cosine_sim):\n",
    "    # Index of the book that matches the title\n",
    "    idx = data.index[data['Book Name'] == book_name].tolist()[0]\n",
    "\n",
    "    # Get pairwise similarity scores \n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sorting books based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get indices of most similar books\n",
    "    sim_scores = sim_scores[1:11] \n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    return data['Book Name'].iloc[book_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine Content-based and Collaborative Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to combine content-based and collaborative filtering recommendations\n",
    "def combine_recommendations(content_recommendations, collaborative_recommendations):\n",
    "    # Combine both recommendations and remove duplicates\n",
    "    combined_recommendations = list(set(content_recommendations) | set(collaborative_recommendations))\n",
    "    \n",
    "    # Return the combined recommendations\n",
    "    return combined_recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Recommended Books:\n",
      "The E-Myth Revisited: Why Most Small Businesses Don't Work and What to Do About It\n",
      "Atomic Habits: An Easy and Proven Way to Build Good Habits and Break Bad Ones\n",
      "Losing My Virginity\n",
      "Life's Amazing Secrets: How to Find Balance and Purpose in Your Life\n",
      "Crime and Punishment\n",
      "Common Stocks and Uncommon Profits\n",
      "Ikigai: The Japanese Secret to a Long and Happy Life\n",
      "Living with the Himalayan Masters\n",
      "The Subtle Art of Not Giving a F*ck: A Counterintuitive Approach to Living a Good Life\n",
      "O Jerusalem: Day by Day and Minute by Minute the Historic Struggle for Jerusalem and the Birth of Israel\n",
      "The Alchemist: A Fable About Following Your Dream\n",
      "The Fountainhead\n",
      "Think and Grow Rich\n",
      "Think Like a Monk: The Secret of How to Harness the Power of Positivity and Be Happy Now\n",
      "Surely You're Joking, Mr. Feynman!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\DELL\\Desktop\\audible_insights\\data\\cleaned_books.csv')\n",
    "\n",
    "# Ensure 'Description' column has no NaN values\n",
    "data['Description'] = data['Description'].fillna('')\n",
    "\n",
    "# 'Description' column for content-based filtering\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(data['Description'])  # Using 'Description' column\n",
    "\n",
    "# cosine similarity to calculate similarity between books\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# content-based recommendations\n",
    "def get_content_based_recommendations(book_name, cosine_sim):\n",
    "    # chwecking bookname in the dataset\n",
    "    if book_name not in data['Book Name'].values:\n",
    "        return f\"Error: Book '{book_name}' not found in dataset.\"\n",
    "    \n",
    "    # Get the index of the book that matches the title\n",
    "    idx = data.index[data['Book Name'] == book_name].tolist()[0]\n",
    "\n",
    "    # pairwise similarity scores books\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the books based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the indices of the most similar books\n",
    "    sim_scores = sim_scores[1:11]  # Get top 10 similar books\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar books\n",
    "    return data['Book Name'].iloc[book_indices]\n",
    "\n",
    "# Collaborative Filtering Model using Nearest Neighbors (KNN)\n",
    "knn = NearestNeighbors(n_neighbors=5, metric='cosine')\n",
    "knn.fit(tfidf_matrix)\n",
    "\n",
    "# Function for collaborative filtering (example)\n",
    "def get_collaborative_filtering_recommendations(user_id):\n",
    "    # collaborative filtering logic,books based on some collaborative filtering logic\n",
    "\n",
    "    return data['Book Name'].head(5)  # Example placeholder\n",
    "\n",
    "# combining content-based and collaborative filtering\n",
    "def combine_recommendations(content_recommendations, collaborative_recommendations):\n",
    "    # Combine the two lists (you can refine the combination method)\n",
    "    return list(set(content_recommendations).union(set(collaborative_recommendations)))\n",
    "\n",
    "# Example usage:\n",
    "book_name = 'Extraordinary Leadership'  # book name from your dataset\n",
    "user_id = 0  # actual user ID\n",
    "\n",
    "# content-based recommendations of existing books\n",
    "content_recommendations = get_content_based_recommendations(book_name, cosine_sim)\n",
    "\n",
    "# If book not found, returns error message\n",
    "if isinstance(content_recommendations, str):  # Check if it's an error message\n",
    "    print(content_recommendations)\n",
    "else:\n",
    "    # collaborative filtering recommendations (assuming you have a user-item matrix)\n",
    "    collaborative_recommendations = get_collaborative_filtering_recommendations(user_id)\n",
    "\n",
    "    # Combine results from both approaches\n",
    "    hybrid_recommendations = combine_recommendations(content_recommendations, collaborative_recommendations)\n",
    "\n",
    "    # hybrid recommendations\n",
    "    print(\"Hybrid Recommended Books:\")\n",
    "    for book in hybrid_recommendations:\n",
    "        print(book)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting Everything Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Recommended Books:\n",
      "The E-Myth Revisited: Why Most Small Businesses Don't Work and What to Do About It\n",
      "Atomic Habits: An Easy and Proven Way to Build Good Habits and Break Bad Ones\n",
      "Losing My Virginity\n",
      "Life's Amazing Secrets: How to Find Balance and Purpose in Your Life\n",
      "Crime and Punishment\n",
      "Common Stocks and Uncommon Profits\n",
      "Ikigai: The Japanese Secret to a Long and Happy Life\n",
      "Living with the Himalayan Masters\n",
      "The Subtle Art of Not Giving a F*ck: A Counterintuitive Approach to Living a Good Life\n",
      "O Jerusalem: Day by Day and Minute by Minute the Historic Struggle for Jerusalem and the Birth of Israel\n",
      "The Alchemist: A Fable About Following Your Dream\n",
      "The Fountainhead\n",
      "Think and Grow Rich\n",
      "Think Like a Monk: The Secret of How to Harness the Power of Positivity and Be Happy Now\n",
      "Surely You're Joking, Mr. Feynman!\n"
     ]
    }
   ],
   "source": [
    "book_name = 'Extraordinary Leadership'\n",
    "user_id = 0  # Replace with actual user ID\n",
    "\n",
    "# content-based recommendations\n",
    "content_recommendations = get_content_based_recommendations(book_name, cosine_sim)\n",
    "\n",
    "# collaborative filtering recommendations (assuming you have a user-item matrix)\n",
    "collaborative_recommendations = get_collaborative_filtering_recommendations(user_id)\n",
    "\n",
    "# Combine results both approaches\n",
    "hybrid_recommendations = combine_recommendations(content_recommendations, collaborative_recommendations)\n",
    "\n",
    "# hybrid recommendations\n",
    "print(\"Hybrid Recommended Books:\")\n",
    "for book in hybrid_recommendations:\n",
    "    print(book)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluate the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance with example\n",
    "y_true = [1, 0, 1, 0, 1]  # True labels (1 for relevant, 0 for irrelevant)\n",
    "y_pred = [1, 0, 0, 1, 1]  # Predicted labels\n",
    "\n",
    "# precision and recall\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "\n",
    "# RMSE for collaborative filtering \n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Book Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books(user_preferences):\n",
    "    content_recommendations = get_content_based_recommendations(user_preferences)\n",
    "    collaborative_recommendations = get_collaborative_filtering_recommendations(user_preferences)\n",
    "    \n",
    "    # Combined final recommendations\n",
    "    return hybrid_recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knn_model.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(kmeans, 'kmeans_model.pkl')\n",
    "joblib.dump(knn, 'knn_model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
